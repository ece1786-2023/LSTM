{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T19:43:45.315251400Z",
     "start_time": "2023-11-19T19:43:41.853227900Z"
    }
   },
   "id": "66bc49d816b9c4bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db232cce0b08135b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "# Add special tokens\n",
    "token_name = \"[PAWN_nameDef]\"\n",
    "token_possessive =\"[PAWN_possessive]\"\n",
    "token_pronoun =\"[PAWN_pronoun]\"\n",
    "\n",
    "# Fine-tuning parameters\n",
    "epochs = 10\n",
    "learning_rate = 5e-5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device \"+str(device))\n",
    "\n",
    "#the model to load from\n",
    "model_name_load=\"gpt2\" #get a fresh gpt-2 model from hugging face\n",
    "#model_name_load=\"ft1\" #load a previously saved model\n",
    "\n",
    "#the model to save as\n",
    "model_name_save=\"ft1\" #get a fresh gpt-2 model from hugging face\n",
    "\n",
    "# data_file_path=\"raw_data/backstory.csv\"\n",
    "data_file_path=\"raw_data/backstory.pkl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T19:43:45.961526500Z",
     "start_time": "2023-11-19T19:43:45.911770500Z"
    }
   },
   "id": "2ae652ef10fd894e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading \n",
    "## Load Tokenizer and Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "750c512e92a3b884"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_load)\n",
    "#TODO attention mask and the pad token id\n",
    "#The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
    "#Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_load).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T19:43:50.066746200Z",
     "start_time": "2023-11-19T19:43:47.393830600Z"
    }
   },
   "id": "5caab897e20d9bbf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1dda391e0c5f9e0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Define a custom dataset class for your sentences\n",
    "class RimWordDS(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences[idx])\n",
    "        inputs = self.tokenizer(sentence, return_tensors=\"pt\", max_length=self.max_length, truncation=True)\n",
    "        return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T19:43:51.097195300Z",
     "start_time": "2023-11-19T19:43:51.086088100Z"
    }
   },
   "id": "a2934f38d1312178"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0f81dd73e944e68"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Title                   Name  \\\n0               sewer kid             SewerKid57   \n1          navy scientist        NavyScientist52   \n2     glitterworld empath   GlitterworldEmpath26   \n3    glitterworld surgeon  GlitterworldSurgeon15   \n4                novelist              Novelist7   \n..                    ...                    ...   \n757        budding artist        BuddingArtist44   \n758                 bully                Bully70   \n759              bookworm             Bookworm19   \n760                  punk   TynanCustomChildhood   \n761        game developer   TynanCustomAdulthood   \n\n                                                  Desc  \\\n0    [PAWN_nameDef] grew up in the sludge-smeared s...   \n1    Interstellar warfare is won by technology, so ...   \n2    [PAWN_nameDef] had an amazing ability to relat...   \n3    [PAWN_nameDef] worked as a surgeon on a world ...   \n4    [PAWN_nameDef] lived on a glitterworld, pennin...   \n..                                                 ...   \n757  [PAWN_nameDef] had a knack for art. Traders an...   \n758  [PAWN_nameDef] tormented other children for fu...   \n759  Rather than socialize with the other children,...   \n760  [PAWN_nameDef] spent his childhood selling kno...   \n761  [PAWN_nameDef] was an independent game develop...   \n\n                                  Attribute  \n0                               Cooking+2\\t  \n1                          Intellectual+8\\t  \n2                    Social+8\\tMedicine+2\\t  \n3        Artistic+5\\tMedicine+3\\tSocial+1\\t  \n4    Construction-5\\tMining-5\\tArtistic+8\\t  \n..                                      ...  \n757                            Artistic+5\\t  \n758                   Melee+2\\tShooting+3\\t  \n759  Intellectual+6\\tArtistic+2\\tSocial-3\\t  \n760              Intellectual-2\\tSocial-2\\t  \n761              Construction-2\\tMining-2\\t  \n\n[762 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Name</th>\n      <th>Desc</th>\n      <th>Attribute</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sewer kid</td>\n      <td>SewerKid57</td>\n      <td>[PAWN_nameDef] grew up in the sludge-smeared s...</td>\n      <td>Cooking+2\\t</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>navy scientist</td>\n      <td>NavyScientist52</td>\n      <td>Interstellar warfare is won by technology, so ...</td>\n      <td>Intellectual+8\\t</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>glitterworld empath</td>\n      <td>GlitterworldEmpath26</td>\n      <td>[PAWN_nameDef] had an amazing ability to relat...</td>\n      <td>Social+8\\tMedicine+2\\t</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>glitterworld surgeon</td>\n      <td>GlitterworldSurgeon15</td>\n      <td>[PAWN_nameDef] worked as a surgeon on a world ...</td>\n      <td>Artistic+5\\tMedicine+3\\tSocial+1\\t</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>novelist</td>\n      <td>Novelist7</td>\n      <td>[PAWN_nameDef] lived on a glitterworld, pennin...</td>\n      <td>Construction-5\\tMining-5\\tArtistic+8\\t</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>757</th>\n      <td>budding artist</td>\n      <td>BuddingArtist44</td>\n      <td>[PAWN_nameDef] had a knack for art. Traders an...</td>\n      <td>Artistic+5\\t</td>\n    </tr>\n    <tr>\n      <th>758</th>\n      <td>bully</td>\n      <td>Bully70</td>\n      <td>[PAWN_nameDef] tormented other children for fu...</td>\n      <td>Melee+2\\tShooting+3\\t</td>\n    </tr>\n    <tr>\n      <th>759</th>\n      <td>bookworm</td>\n      <td>Bookworm19</td>\n      <td>Rather than socialize with the other children,...</td>\n      <td>Intellectual+6\\tArtistic+2\\tSocial-3\\t</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>punk</td>\n      <td>TynanCustomChildhood</td>\n      <td>[PAWN_nameDef] spent his childhood selling kno...</td>\n      <td>Intellectual-2\\tSocial-2\\t</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>game developer</td>\n      <td>TynanCustomAdulthood</td>\n      <td>[PAWN_nameDef] was an independent game develop...</td>\n      <td>Construction-2\\tMining-2\\t</td>\n    </tr>\n  </tbody>\n</table>\n<p>762 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load prepocessed data\n",
    "# Load your DataFrame with sentences\n",
    "# For example, you can load your data like this:\n",
    "# df = pd.read_csv(data_file_path,encoding=\"unicode_escape\")\n",
    "# titles=df[\"Title\"]\n",
    "# sentences = df[\"Desc\"].tolist()\n",
    "# print(sentences)\n",
    "# len_data=len(titles)\n",
    "\n",
    "import pandas as pd\n",
    "# data_file_path=\"backstory.pkl\"\n",
    "df = pd.read_pickle(data_file_path)\n",
    "titles=df[\"Title\"]\n",
    "sentences = df[\"Desc\"]\n",
    "sentences = sentences.tolist()\n",
    "len_data=len(titles)\n",
    "\n",
    "for i in range(len_data):\n",
    "    #print(i,type(sentences[i]),str(sentences[i])) \n",
    "    sentences[i]=\"This is the story of [PAWN_nameDef], a \"+titles[i]+\": \"+sentences[i]\n",
    "    # TODO attributes\n",
    "\n",
    "#convert backstroy into proper prompt\n",
    "\n",
    "\n",
    "sentences_train, sentences_test = train_test_split(sentences, test_size=0.05, random_state=42)\n",
    "\n",
    "# Create a custom dataset\n",
    "dataset_train = RimWordDS(sentences_train, tokenizer)\n",
    "dataset_test = RimWordDS(sentences_test, tokenizer)\n",
    "\n",
    "# TODO cross validation?\n",
    "\"\"\"\n",
    "# Split the dataframe into train and test sets, with a test size of 0.03\n",
    "train, test = train_test_split(df, test_size=0.03, random_state=42)\n",
    "\n",
    "# Create a cross-validation iterator with 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "print(sentences[20])\n",
    "print(sentences[21])\n",
    "print(sentences[22])\"\"\"\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T19:48:21.440789400Z",
     "start_time": "2023-11-19T19:48:21.402616300Z"
    }
   },
   "id": "3e30d10696391813"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training\n",
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a8fdde8b991f2a9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|██████████| 723/723 [01:11<00:00, 10.11it/s, Loss=1.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 /10: Test loss= 1.8242541796121843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 723/723 [01:13<00:00,  9.80it/s, Loss=1.31] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 /10: Test loss= 1.8971435198417077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 723/723 [01:14<00:00,  9.68it/s, Loss=1.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 /10: Test loss= 2.0195577389154677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 723/723 [01:16<00:00,  9.41it/s, Loss=0.832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 /10: Test loss= 2.185129260405516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 723/723 [01:18<00:00,  9.21it/s, Loss=0.662] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 /10: Test loss= 2.3678681453069053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 723/723 [01:19<00:00,  9.13it/s, Loss=0.517] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 /10: Test loss= 2.510829604589022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 723/723 [01:21<00:00,  8.84it/s, Loss=0.418] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 /10: Test loss= 2.6898797230842786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 723/723 [01:24<00:00,  8.56it/s, Loss=0.34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 /10: Test loss= 2.717543834295028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 723/723 [01:22<00:00,  8.71it/s, Loss=0.29]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 /10: Test loss= 2.77341178441659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 723/723 [01:24<00:00,  8.53it/s, Loss=0.251] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 /10: Test loss= 2.8852270199702335\n"
     ]
    }
   ],
   "source": [
    "# Add custom tokens to tokenizer\n",
    "#tokenizer.add_tokens([token_name,token_possessive,token_pronoun])\n",
    "\"\"\"model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# five fold cross validation\n",
    "# Loop over the train set and the cross-validation iterator\n",
    "for train_index, val_index in kf.split(train):\n",
    "    # Get the train and validation sets for each fold\n",
    "    train_fold = train.iloc[train_index]\n",
    "    val_fold = train.iloc[val_index]\n",
    "    # Training process\n",
    "\n",
    "train_fold\"\"\"\n",
    "\n",
    "# Set up DataLoader\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=True)\n",
    "#TODO padding to allow batching\n",
    "dataloader_train_len=len(dataloader_train)\n",
    "dataloader_test_len=len(dataloader_test)\n",
    "\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "#TODO optimizer selection\n",
    "\n",
    "loss_ot_train=np.zeros(epochs)\n",
    "loss_ot_test=np.zeros(epochs)\n",
    "\n",
    "# Fine-tune loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss_train = 0\n",
    "    total_loss_test = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_train, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        batch = {key: value[0].to(device) for key, value in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch, labels=batch[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_train += loss.item()\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"Loss\": total_loss_train / dataloader_train_len})\n",
    "\n",
    "    for batch_idx, batch in enumerate(dataloader_test, 1):\n",
    "        # Move batch to device\n",
    "        batch = {key: value[0].to(device) for key, value in batch.items()}\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(**batch, labels=batch[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "    \n",
    "        total_loss_test += loss.item()\n",
    "    total_loss_test /= dataloader_test_len\n",
    "    print(\"Epoch \",epoch,\"/10: Test loss=\",total_loss_test)\n",
    "    \n",
    "    #record loss of the epoch\n",
    "    loss_ot_train[epoch]=total_loss_train/dataloader_train_len\n",
    "    loss_ot_test[epoch]=total_loss_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:01:40.929368600Z",
     "start_time": "2023-11-19T19:48:23.057510Z"
    }
   },
   "id": "5d485454ae886ac8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot Loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d44173cc0d9c2adb"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, splot = plt.subplots(1)\n",
    "domain = np.arange(epochs)\n",
    "splot.plot(domain, loss_ot_train, 'g',label=\"train\")\n",
    "splot.plot(domain, loss_ot_test, 'r',label=\"test\")\n",
    "splot.legend()\n",
    "splot.title.set_text(\"Loss over time\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:02:45.354635400Z",
     "start_time": "2023-11-19T20:02:45.205703900Z"
    }
   },
   "id": "4e48fcea5f0815c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the fine-tuned model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5a438125c7799f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'models/model_v1.pt')\n",
    "\n",
    "model.save_pretrained(model_name_save)\n",
    "tokenizer.save_pretrained(model_name_save)\n",
    "\n",
    "#TODO truncate model to under 100MB? save state dict only?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "366ce5c632d79ffa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Note Area\n",
    "\n",
    "1. asn3 mingpt\n",
    "2. asn3 hugging face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3d0f4e1db2bf892"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing Area\n",
    "just ignore"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd3cdf6c87d09870"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['This is the story of [PAWN_nameDef], a renegade engineer: After a daring escape from the prison planet with a small crew of fellow inmates, [PAWN_nameDef] set [PAWN_possessive] gaze on [PAWN_possessive] homeworld.\\n\\n[PAWN_pronoun] travelled there, recruited more followers, hijacked a space cruiser, and launched into the void.',\n 'This is the story of [PAWN_nameDef], a bounty hunter: [PAWN_nameDef] was a bounty hunter on a massive glitterworld. [PAWN_pronoun] worked sensitive assignments for extremely wealthy clients, and was known for quiet execution and total discretion.',\n 'This is the story of [PAWN_nameDef], a gardener: [PAWN_nameDef] worked at the mansion of a powerful family, tending the lavish gardens as part of a team of servants.',\n 'This is the story of [PAWN_nameDef], a nerd: [PAWN_nameDef] was curious about everything. While other kids played tag in the suburbs of their industrial city, [PAWN_nameDef] read every book [PAWN_pronoun] could find about technology, robots, and weapons - whatever looked coolest.\\n\\n[PAWN_possessive] strong French accent kept [PAWN_objective] from making real friends.',\n 'This is the story of [PAWN_nameDef], a kid scientist: Born into an influential family, [PAWN_nameDef] received the best education money could buy. [PAWN_possessive] intellect soon proved to be superior to many. However, [PAWN_possessive] lack of empathy quickly put [PAWN_objective] at odds with [PAWN_possessive] teachers and [PAWN_possessive] parents.',\n 'This is the story of [PAWN_nameDef], a tournament fighter: Motivated by the violence in [PAWN_possessive] environment, [PAWN_nameDef] studied martial arts, eventually signing up for an unarmed fighting tournament.\\n\\n        Unlike [PAWN_possessive] opponents, [PAWN_nameDef] looked to the ancient warriors for guidance. [PAWN_pronoun] trained from dusk till dawn, perfecting [PAWN_possessive] skills.',\n 'This is the story of [PAWN_nameDef], a tragic loner: [PAWN_nameDef] was involved in a traumatic accident that resulted in [PAWN_objective] killing [PAWN_possessive] own family.\\n\\nCast out from society, [PAWN_pronoun] was left with only [PAWN_possessive] animal companions and several engineering textbooks to keep [PAWN_objective] company.',\n 'This is the story of [PAWN_nameDef], a army cook: [PAWN_nameDef] joined the army as a worker and spent most of [PAWN_possessive] time cooking and repairing. While [PAWN_pronoun] was stationed on a dangerous planet, [PAWN_pronoun] underwent basic shooting and survival training.',\n 'This is the story of [PAWN_nameDef], a class clown: In the ultra-competitive environs of [PAWN_possessive] glitterworld school, [PAWN_nameDef] always offered to play the class clown to diffuse tension.\\n\\n[PAWN_pronoun] developed a sense of social desperation from this, as well as an appreciation for the artistic side of comedy.',\n 'This is the story of [PAWN_nameDef], a hermit: Worn out by the pressures of social interaction, [PAWN_nameDef] left [PAWN_possessive] crowded city to live a simple life in the wilderness. There, [PAWN_pronoun] spent [PAWN_possessive] days alone, tending [PAWN_possessive] garden and crafting the simple tools [PAWN_pronoun] needed to survive.',\n 'This is the story of [PAWN_nameDef], a crop farmer: [PAWN_nameDef] ran a crop farm. [PAWN_pronoun] analyzed soil, agricultural equipment, weather patterns, and price trends to optimize the planting and harvesting of massive crop fields.',\n 'This is the story of [PAWN_nameDef], a glitterworld nerd: [PAWN_nameDef] loved technology from the day [PAWN_pronoun] was born. [PAWN_pronoun] had a mechanoid companion which [PAWN_pronoun] tried to modify.\\n\\n[PAWN_possessive] obsession with technology meant that [PAWN_pronoun] never appreciated arts or culture.',\n 'This is the story of [PAWN_nameDef], a beast slayer: [PAWN_nameDef] traveled between planets, following news of animal attacks. [PAWN_pronoun] would camp on the planet for weeks, learning about [PAWN_possessive] prey before striking. [PAWN_pronoun] most enjoyed hunting thrumbos.\\n\\nPreferring to work alone, [PAWN_nameDef] enjoyed the thrill of the hunt, and the meat from the kill.',\n 'This is the story of [PAWN_nameDef], a envoy of the stars: [PAWN_nameDef] entered the diplomatic corps. Honor and tradition were the values [PAWN_pronoun] took with [PAWN_objective] on every mission.\\n\\n[PAWN_possessive] prestigious position distanced [PAWN_objective] from backbreaking manual labor, allowing [PAWN_objective] to focus on [PAWN_possessive] wordsmithing abilities. [PAWN_pronoun] left the blacksmithing to others.',\n 'This is the story of [PAWN_nameDef], a discarded youth: [PAWN_nameDef] grew up isolated on a trash planet. A dumping ground for surrounding glitterworlds, it was a harsh home. As a baby, [PAWN_pronoun] sucked on the tap of a discarded nutrient paste dispenser for comfort.\\n\\nIn these desperate circumstances, against all odds, [PAWN_pronoun] survived - and thrived.',\n 'This is the story of [PAWN_nameDef], a engineer: [PAWN_nameDef] found a job as a tinkering engineer on the trading hub planet Irithir. Tough local traders forced [PAWN_objective] to learn negotiation skills, and [PAWN_pronoun] made good profits selling refurbished weapons and tools.',\n 'This is the story of [PAWN_nameDef], a station security: [PAWN_nameDef] was commissioned as a special constable on a network of space stations. There [PAWN_pronoun] prevented illegal human trafficking.\\n\\nOnce, fire broke out on the station, and [PAWN_pronoun] saved many from the flames. Since then, [PAWN_pronoun] has avoided fires.',\n 'This is the story of [PAWN_nameDef], a destroyer-general: [PAWN_nameDef] held the rank of Destroyer-General in a powerful midworld military.\\n\\n[PAWN_pronoun] was known for [PAWN_possessive] mastery of weapons, and was also a good ship pilot.',\n 'This is the story of [PAWN_nameDef], a mechanoid nerd: [PAWN_nameDef] grew up in an urbworld as the only child of a pair of mechanoid designers.\\nThey encouraged [PAWN_possessive] interest in the machines. Eventually, [PAWN_pronoun] became obsessed with building [PAWN_possessive] own.\\n\\nUnfortunately this also lead to [PAWN_objective] being a loner as [PAWN_pronoun] prefered technical books to friends.',\n \"This is the story of [PAWN_nameDef], a factory drone: [PAWN_nameDef] grew up in a large factory city on an industrial world.\\n\\nSince poverty was rampant and food scarce, [PAWN_pronoun] worked for whatever wages [PAWN_pronoun] could get. This wasn't an easy life, but [PAWN_nameDef] never shied away from a hard day's work.\",\n 'This is the story of [PAWN_nameDef], a bloody wanderer: [PAWN_nameDef] was a wanderer, traveling from town to town, taking odd jobs and stealing to live.\\n\\nOne day, [PAWN_pronoun] had a mental break and went on a long rampage, destroying several towns and killing many. [PAWN_pronoun] eventually calmed, but [PAWN_possessive] bloodlust never left [PAWN_objective].',\n 'This is the story of [PAWN_nameDef], a athlete: [PAWN_nameDef] was professional athlete at early age. Thanks to [PAWN_possessive] skills, [PAWN_pronoun] was able to leave [PAWN_possessive] homeworld and enroll in a glitterworld university of science and technology.\\n\\nBecause of [PAWN_possessive] demanding schedule and introverted nature, [PAWN_pronoun] became socially inept.',\n 'This is the story of [PAWN_nameDef], a empath: [PAWN_nameDef] was an incredibly empathetic child, so much that [PAWN_pronoun] was totally overwhelmed by simple social interactions. Once, [PAWN_pronoun] stepped on a bug and felt so guilty [PAWN_pronoun] cried for an hour.\\n\\n[PAWN_nameDef] did try to use a gun one time, but it went very poorly, as the loud noise made [PAWN_objective] flinch uncontrollably.',\n \"This is the story of [PAWN_nameDef], a medieval squire: [PAWN_nameDef] grew up on a medieval planet as a knight in training. [PAWN_pronoun] trained directly under the king's war adviser for most of [PAWN_possessive] youth, and learned to fight with a sword and shield.\",\n 'This is the story of [PAWN_nameDef], a rebel slave: [PAWN_nameDef] was born into corporate slavery and raised to perform menial tasks for minimum pay. [PAWN_pronoun] was just another cog in the machine. \\n\\n[PAWN_nameDef] found [PAWN_possessive] freedom by joining a rebel organization whose goal was to break free from their corporate masters.',\n 'This is the story of [PAWN_nameDef], a foundry apprentice: [PAWN_nameDef] grew up as an apprentice in the foundries of an industrial world. This experience gave [PAWN_objective] metalworking skills and strong muscles, but stunted [PAWN_possessive] artistic development.',\n 'This is the story of [PAWN_nameDef], a game fanatic: [PAWN_nameDef] was a fanatical gamer who learned to survive in virtual reality games.\\n\\nOnce, while attempting to prove [PAWN_possessive] skills in the real world, [PAWN_pronoun] was abducted by a criminal scientist and experimented on. [PAWN_pronoun] escaped, but the experience stayed with him.',\n 'This is the story of [PAWN_nameDef], a mechanics engineer: [PAWN_nameDef] loved solving problems and, with [PAWN_possessive] steady hands and a reputation for quality work, earned a job as a mechanical engineer. [PAWN_pronoun] built and redesigned devices of all shapes and sizes.\\n\\nEventually, [PAWN_pronoun] was able to pick and choose [PAWN_possessive] corporate clients. [PAWN_pronoun] made several wealthy friends, as well as a few powerful enemies.',\n \"This is the story of [PAWN_nameDef], a traders' child: [PAWN_nameDef] grew up in a family of nomadic traders, making a living from selling and buying goods on many worlds.\\n\\n[PAWN_nameDef] learned the customs and methods of trade of many cultures by participating in [PAWN_possessive] parents' business.\",\n 'This is the story of [PAWN_nameDef], a ice planet child: Growing up on the frozen wastes of an ocean moon, [PAWN_nameDef] only had animals and a few hard-bitten sailors as companions.\\n\\nThe lack of social interaction made [PAWN_objective] develop a interest in engineering - but [PAWN_pronoun] never developed any great fondness for humans.',\n 'This is the story of [PAWN_nameDef], a child scientist: After graduating college very young, [PAWN_nameDef] devoted [PAWN_possessive] life to becoming immortal. [PAWN_pronoun] was arrested for trying to genetically modify [PAWN_objective]self.\\n\\nThe authorities released [PAWN_objective] on the condition that [PAWN_pronoun] would work in a government lab on spacecraft technology. [PAWN_pronoun] was permitted to continue [PAWN_possessive] personal research in [PAWN_possessive] free time.',\n \"This is the story of [PAWN_nameDef], a young psychologist: [PAWN_nameDef] was born and raised on a poor midworld, in the front passenger seat of [PAWN_possessive] mother's cab.\\n\\nWatching pedestrians and listening to the taxi passengers all day long, [PAWN_pronoun] soon became very good at figuring out someone's real purpose.\",\n 'This is the story of [PAWN_nameDef], a child star: [PAWN_nameDef] was well-known throughout [PAWN_possessive] homeworld as a child actor in films and TV shows. [PAWN_possessive] fame put [PAWN_objective] in contact with many different kinds of people, but also tended to get in the way of [PAWN_possessive] education.',\n \"This is the story of [PAWN_nameDef], a star squire: Born on a medieval world, [PAWN_nameDef]'s first memory is of gazing up into the night's sky. \\n\\nEver since, [PAWN_pronoun] dreamed of squiring for a knight amidst the star-filled heavens. [PAWN_possessive] focus on that vision left [PAWN_objective] somewhat single-minded.\",\n 'This is the story of [PAWN_nameDef], a evangelist: As a youth, [PAWN_nameDef] experienced a religious awakening. [PAWN_pronoun] decided to spend the rest of [PAWN_possessive] life spreading the word of [PAWN_possessive] deity, the beauty of its culture, and its unusual medical tradition.',\n 'This is the story of [PAWN_nameDef], a craft shaper: [PAWN_nameDef] locked [PAWN_objective]self in [PAWN_possessive] studio for years, ordering delivery food to save time on cooking.\\n\\nEventually, [PAWN_possessive] creations brought [PAWN_objective] the highest honor on Semantic World: Permission to materialize any design in minutes using the most advanced technologies.',\n \"This is the story of [PAWN_nameDef], a mad scientist: After finishing [PAWN_possessive] education, [PAWN_nameDef] was hired by the planet's leading genetic researcher. Later, [PAWN_pronoun] was caught running illegal, inhumane experiments.\\n\\nDespite [PAWN_possessive] family's influence, [PAWN_pronoun] was convicted and sentenced to hard labor on a penal colony.\",\n \"This is the story of [PAWN_nameDef], a reclusive child: [PAWN_nameDef] didn't learn to speak until [PAWN_pronoun] was nearly five years old. Even then [PAWN_pronoun] preferred to keep to [PAWN_objective]self.\\n\\\\nTo the chagrin of [PAWN_possessive] caretakers, [PAWN_pronoun] made a habit of wandering off to live in the wilderness for weeks at a time.\",\n 'This is the story of [PAWN_nameDef], a desert rat: [PAWN_nameDef] was born to a tribe of desert ascetics who wandered the endless wastes.\\n\\nThey sought a mythical substance they believed could liberate them from ignorance through psychedelic revelation - and usher in a new period of interstellar peace.']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:03:05.336102700Z",
     "start_time": "2023-11-19T20:03:05.331447100Z"
    }
   },
   "id": "f10a2998fe2ea6ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "#dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "dataset = train_dataset\n",
    "\n",
    "# Preprocess the dataset\n",
    "def encode(examples):\n",
    "    input_ids = tokenizer(examples[\"text\"], return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "    labels = input_ids.clone()\n",
    "    return {\"input_ids\": input_ids, \"labels\": labels}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "dataset = dataset.map(encode, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    ")\n",
    "\n",
    "# Create a trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4d68d389c4a2ae3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "#from mingpt.bpe import BPETokenizer\n",
    "#from mingpt.utils import set_seed\n",
    "#set_seed(1234)\n",
    "\"\"\"\n",
    "Prepare the dataset to train the Language Model (LM)\n",
    "This implementation splits the sentences and so doesn't create training \n",
    "examples that cross sentences.\n",
    "\n",
    "This code is set so that it uses one of two possible datasets, which were also used in Assignment 1: \n",
    "SmallSimpleCorpus.txt or LargerCorpus.txt\n",
    "\n",
    "Arguments:\n",
    "            ds_choice: str. \"small\" or \"large\". (i.e. selects which of the two datasets)\n",
    "            split: str. \"train\" or \"test\".\n",
    "            truncation: int. If -1: no truncation on sentences. Otherwise: truncate to this specific length.\n",
    "\"\"\"\n",
    "\n",
    "class LanguageModelingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds_choice=\"small\", split=\"train\", truncation=-1):\n",
    "\n",
    "        base_path = \"./\"\n",
    "        fn = {\"small\": \"raw_data/backstory.csv\", \"large\": \"LargerCorpus.txt\"}\n",
    "        self.ds_choice = ds_choice\n",
    "        self.truncation = truncation  # int. If -1, then\n",
    "        text = Path(base_path, fn[ds_choice]).read_text()#encoding='utf-8')\n",
    "        if ds_choice == \"large\":\n",
    "            # Remove the newline char in the middle of sentences\n",
    "            # The \"paragraph splitting\" newlines appear to be \\n\\n -- remove the duplications there\n",
    "            text = text.replace(\"\\n\\n\", \"$$^^$$\").replace(\"\\n\", \" \").replace(\"$$^^$$\", \"\\n\")\n",
    "        sentences = sent_tokenize(text)\n",
    "        for i in range(10):\n",
    "            print(sentences[i])\n",
    "\n",
    "        # Train / test split\n",
    "        train, val = train_test_split(sentences, test_size=0.2, shuffle=False)\n",
    "        if split == \"train\":\n",
    "            raw_data = train\n",
    "        else:\n",
    "            raw_data = val\n",
    "\n",
    "            # Tokenize\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = []  # List of 1-d pytorch tensor\n",
    "        for sent in raw_data:\n",
    "            tokenized = self.tokenizer(sent).view(-1)  # pytorch tensor\n",
    "            if truncation >= 0:\n",
    "                self.data.append(tokenized[:truncation])\n",
    "            else:\n",
    "                self.data.append(tokenized)\n",
    "\n",
    "        # Count some items\n",
    "        self.max_sentence_length = np.max([len(d) for d in self.data])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        \"\"\"\n",
    "        We have to set this to the max vocab size (i.e., that decided by the BPE tokenizer), \n",
    "        but actually, only a small number of vocab is used, especially for the small text. \n",
    "        \"\"\"\n",
    "        return 50257\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        The output should be a tuple x and y, both as pytorch tensors.\n",
    "        Please refer to the `run()` method in the mingpt/trainer.py script for \n",
    "        how the x and y are going to be used.\n",
    "        \"\"\"\n",
    "        x = self.data[idx][:-1]\n",
    "        y = self.data[idx][1:]\n",
    "        return (x, y)\n",
    "\n",
    "    def get_block_size(self):\n",
    "        \"\"\"\n",
    "        block_size is the size at which lines are truncated to ensure they are equal-length.\n",
    "        \"\"\"\n",
    "        return self.max_sentence_length\n",
    "\n",
    "# Instantiate the Training Dataset\n",
    "#train_dataset = LanguageModelingDataset(ds_choice=\"small\", split=\"train\")  # use this for the short corpus\n",
    "train_dataset = LanguageModelingDataset(ds_choice=\"small\", split=\"train\", truncation=512) #use this for long\n",
    "\n",
    "# Instantiate a Validation Dataset (this is only really needed for the fine-tune task, not the LM task)\n",
    "#val_dataset = LanguageModelingDataset(ds_choice=\"small\", split=\"validation\")\n",
    "#val_dataset = LanguageModelingDataset(ds_choice=\"large\", split=\"validation\", truncation=512)\n",
    "\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa025a04b730af3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fix tokenize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f923d1487ae284f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "#from mingpt.bpe import BPETokenizer\n",
    "#from mingpt.utils import set_seed\n",
    "#set_seed(1234)\n",
    "\"\"\"\n",
    "Prepare the dataset to train the Language Model (LM)\n",
    "This implementation splits the sentences and so doesn't create training \n",
    "examples that cross sentences.\n",
    "\n",
    "This code is set so that it uses one of two possible datasets, which were also used in Assignment 1: \n",
    "SmallSimpleCorpus.txt or LargerCorpus.txt\n",
    "\n",
    "Arguments:\n",
    "            ds_choice: str. \"small\" or \"large\". (i.e. selects which of the two datasets)\n",
    "            split: str. \"train\" or \"test\".\n",
    "            truncation: int. If -1: no truncation on sentences. Otherwise: truncate to this specific length.\n",
    "\"\"\"\n",
    "\n",
    "class LanguageModelingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds_choice=\"small\", split=\"train\", truncation=-1):\n",
    "\n",
    "        base_path = \"./\"\n",
    "        fn = {\"small\": \"raw_data/backstory.csv\", \"large\": \"LargerCorpus.txt\"}\n",
    "        self.ds_choice = ds_choice\n",
    "        self.truncation = truncation  # int. If -1, then\n",
    "        text = Path(base_path, fn[ds_choice]).read_text()#encoding='utf-8')\n",
    "        if ds_choice == \"large\":\n",
    "            # Remove the newline char in the middle of sentences\n",
    "            # The \"paragraph splitting\" newlines appear to be \\n\\n -- remove the duplications there\n",
    "            text = text.replace(\"\\n\\n\", \"$$^^$$\").replace(\"\\n\", \" \").replace(\"$$^^$$\", \"\\n\")\n",
    "        sentences = sent_tokenize(text)\n",
    "        for i in range(10):\n",
    "            print(sentences[i])\n",
    "\n",
    "        # Train / test split\n",
    "        train, val = train_test_split(sentences, test_size=0.2, shuffle=False)\n",
    "        if split == \"train\":\n",
    "            raw_data = train\n",
    "        else:\n",
    "            raw_data = val\n",
    "\n",
    "            # Tokenize\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = []  # List of 1-d pytorch tensor\n",
    "        \n",
    "        for sent in raw_data:\n",
    "            tokenized = self.tokenizer(sent)\n",
    "            print(sent)\n",
    "            print(tokenized)\n",
    "            #tokenized = self.tokenizer(sent).view(-1)  # pytorch tensor\n",
    "            if truncation >= 0:\n",
    "                self.data.append(tokenized[:truncation])\n",
    "            else:\n",
    "                self.data.append(tokenized)\n",
    "\n",
    "        # Count some items\n",
    "        self.max_sentence_length = np.max([len(d) for d in self.data])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        \"\"\"\n",
    "        We have to set this to the max vocab size (i.e., that decided by the BPE tokenizer), \n",
    "        but actually, only a small number of vocab is used, especially for the small text. \n",
    "        \"\"\"\n",
    "        return 50257\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        The output should be a tuple x and y, both as pytorch tensors.\n",
    "        Please refer to the `run()` method in the mingpt/trainer.py script for \n",
    "        how the x and y are going to be used.\n",
    "        \"\"\"\n",
    "        x = self.data[idx][:-1]\n",
    "        y = self.data[idx][1:]\n",
    "        return (x, y)\n",
    "\n",
    "    def get_block_size(self):\n",
    "        \"\"\"\n",
    "        block_size is the size at which lines are truncated to ensure they are equal-length.\n",
    "        \"\"\"\n",
    "        return self.max_sentence_length\n",
    "\n",
    "# Instantiate the Training Dataset\n",
    "#train_dataset = LanguageModelingDataset(ds_choice=\"small\", split=\"train\")  # use this for the short corpus\n",
    "train_dataset = LanguageModelingDataset(ds_choice=\"small\", split=\"train\", truncation=512) #use this for long\n",
    "\n",
    "# Instantiate a Validation Dataset (this is only really needed for the fine-tune task, not the LM task)\n",
    "#val_dataset = LanguageModelingDataset(ds_choice=\"small\", split=\"validation\")\n",
    "#val_dataset = LanguageModelingDataset(ds_choice=\"large\", split=\"validation\", truncation=512)\n",
    "\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0e1ffb5bce46e56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## i have huggingface \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "and a pandas dataframe with a single column where each row represents sentences please write me code that makes it finetune"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d99507d538d66a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0f83a1c5bf9e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt =\"In rimworld, \"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "print(input_ids.get_device())\n",
    "\n",
    "\n",
    "# sample up to 30 tokens\n",
    "torch.manual_seed(11)\n",
    "list_out=[]\n",
    "#['Today I believe we can finally get rid of discrimination,\" said Rep. Mark Pocan (D-Wis.).\\n\\n\"Just look at the']\n",
    "for i in range (1):\n",
    "    for j in range (8):\n",
    "        outputs = model.generate(input_ids, do_sample=True, max_length=30, temperature =1+0.05*i,top_p=1,repetition_penalty=1.1)\n",
    "        list_out.append(outputs)\n",
    "\n",
    "\n",
    "for i in range (1):\n",
    "    for j in range (8):\n",
    "        #print(\"temperature =\",11.6+0.75*i,\"top_p=\",(j+1)/30)\n",
    "        print(tokenizer.batch_decode(list_out[i*4+j], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e159df507808ca7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "330916891f9b4aec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
